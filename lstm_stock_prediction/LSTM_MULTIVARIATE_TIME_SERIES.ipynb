{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series Prediction Using LSTM\n",
    "\n",
    "In this example, we will implement an LSTM using mlpack to forecast multivariate time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking libraries to the Notebook.\n",
    "\n",
    "Link all required libraries to jupyter notebook.\n",
    "I think this section should be removed, Let me know what you think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pragma cling add_library_path(\"/usr/local/lib/\")\n",
    "#pragma cling add_include_path(\"/usr/local/include/\")\n",
    "#pragma cling load(\"/usr/local/Cellar/armadillo/9.850.1_1/lib/libarmadillo.9.85.1.dylib\")\n",
    "#pragma cling load(\"/usr/local/Cellar/armadillo/9.850.1_1/lib/libarmadillo.9.dylib\")\n",
    "#pragma cling load(\"/usr/local/Cellar/armadillo/9.850.1_1/lib/libarmadillo.dylib\")\n",
    "#pragma cling load(\"/usr/local/Cellar/mlpack/3.2.2_2/lib/libmlpack.3.2.dylib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Include all libraries required to implement this tutorial. These mainly include files from mlpack, ensmallen and armadillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mlpack/core.hpp>\n",
    "#include <mlpack/prereqs.hpp>\n",
    "#include <mlpack/methods/ann/rnn.hpp>\n",
    "#include <mlpack/methods/ann/layer/layer.hpp>\n",
    "#include <mlpack/core/data/scaler_methods/min_max_scaler.hpp>\n",
    "#include <mlpack/methods/ann/init_rules/he_init.hpp>\n",
    "#include <mlpack/methods/ann/loss_functions/mean_squared_error.hpp>\n",
    "#include <mlpack/core/data/split_data.hpp>\n",
    "#include <ensmallen.hpp>\n",
    "#include <armadillo>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some convienent namespaces to simplify the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack;\n",
    "using namespace mlpack::ann;\n",
    "using namespace arma;\n",
    "using namespace std;\n",
    "using namespace ens;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Model and Training parameters.\n",
    "\n",
    "Set the training parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// If true, the model will be trained; if false, the saved model will be\n",
    "// read and used for prediction\n",
    "// NOTE: Training the model may take a long time, therefore once it is\n",
    "// trained you can set this to false and use the model for prediction.\n",
    "// NOTE: There is no error checking in this example to see if the trained\n",
    "// model exists!\n",
    "const bool bTrain = true;\n",
    "// You can load and further train a model by setting this to true.\n",
    "const bool bLoadAndTrain = false;\n",
    "\n",
    "// Testing data is taken from the dataset in this ratio.\n",
    "const double RATIO = 0.1;\n",
    "\n",
    "// Step size of an optimizer.\n",
    "const double STEP_SIZE = 5e-5;\n",
    "\n",
    "// Number of cells in the LSTM (hidden layers in standard terms).\n",
    "// NOTE: you may play with this variable in order to further optimize the\n",
    "// model (as more cells are added, accuracy is likely to go up, but training\n",
    "// time may take longer).\n",
    "const int H1 = 25;\n",
    "\n",
    "// Number of data points in each iteration of SGD.\n",
    "const size_t BATCH_SIZE = 16;\n",
    "\n",
    "// Nunmber of timesteps to look backward for in the RNN.\n",
    "const int rho = 25;\n",
    "\n",
    "// Max Rho for LSTM.\n",
    "const int maxRho = rho;\n",
    "\n",
    "// Number of epochs for training.\n",
    "const int EPOCHS = 150;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for the dataset, trained model and final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Change the names of these files as necessary. They should be correct\n",
    "// already, if your program's working directory contains the data and/or\n",
    "// model.\n",
    "const std::string dataFile = \"Google2016-2019.csv\";\n",
    "// Path where the model will be saved.\n",
    "const std::string modelFile = \"lstm_multi.bin\";\n",
    "// Path where the final predicitions will be stored.\n",
    "const std::string predFile = \"lstm_multi_predictions.csv\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Preprocess the Dataset.\n",
    "\n",
    "Dataset will be loaded and preprocessed for the model. If we want to predict the Google stock price correctly then we need to consider the volume of the stocks traded, the closing, opening, high and low values of the stock price from the previous days. This is a time series problem.\n",
    "We will create data for the training of the RNN model that will go back 25 business days in the past for each time step.\n",
    "We will convert the input data to the time series format the RNN requires. We will take 30 % of the latest data as our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data ...\n"
     ]
    }
   ],
   "source": [
    "arma::mat dataset;\n",
    "\n",
    "// In Armadillo rows represent features, columns represent data points.\n",
    "std::cout << \"Reading data ...\" << std::endl;\n",
    "mlpack::data::Load(dataFile, dataset, true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0   2.7000e+01   2.8000e+01   2.9000e+01\n",
      "            0   6.6826e+02   6.8004e+02   6.8411e+02\n",
      "            0   2.6320e+06   2.1697e+06   1.9314e+06\n",
      "            0   6.7100e+02   6.7897e+02   6.8300e+02\n",
      "            0   6.7230e+02   6.8033e+02   6.8743e+02\n",
      "            0   6.6328e+02   6.7300e+02   6.8141e+02\n"
     ]
    }
   ],
   "source": [
    "// Visualize the first 1 rows of the dataset.\n",
    "dataset.submat(0, 0, dataset.n_rows - 1, 3).print()\n",
    "// Here each row represents: date, close, volume, open, high, low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "// The CSV file has a header, so it is necessary to remove it. In Armadillo's\n",
    "// representation it is the first column.\n",
    "// The first column in the CSV is the date which is not required, therefore\n",
    "// we remove it also (first row in in arma::mat).\n",
    "\n",
    "dataset = dataset.submat(1, 1, dataset.n_rows - 1, dataset.n_cols - 1);\n",
    "\n",
    "// We have 5 input data columns and 2 output columns (target).\n",
    "size_t inputSize = 5, outputSize = 2;\n",
    "\n",
    "// Split the dataset into training and validation sets.\n",
    "arma::mat trainData = dataset.submat(arma::span(),arma::span(0, (1 - RATIO) *\n",
    "      dataset.n_cols));\n",
    "arma::mat testData = dataset.submat(arma::span(), arma::span((1 - RATIO) * dataset.n_cols,\n",
    "      dataset.n_cols - 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data needs to be scaled before we train or test the model. This reduces variation in data (normalize the data) and makes the algorithm converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpack::data::MinMaxScaler scale;\n",
    "// Fit scaler only on training data.\n",
    "scale.Fit(trainData);\n",
    "scale.Transform(trainData, trainData);\n",
    "scale.Transform(testData, testData);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Time Series Dataset.\n",
    "\n",
    "The time series data for training the model contains the Closing stock price, the Volume of stocks traded,\n",
    "Opening stock price, Highest stock price and Lowest stock price for 'rho' days in the past. \n",
    "The two target variables (multivariate) we want to predict are the Highest stock price and Lowest stock price\n",
    "(high, low) for the next day! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template<typename InputDataType = arma::mat,\n",
    "         typename DataType = arma::cube,\n",
    "         typename LabelType = arma::cube>\n",
    "void CreateTimeSeriesData(InputDataType dataset,\n",
    "                          DataType& X,\n",
    "                          LabelType& y,\n",
    "                          const size_t rho)\n",
    "{\n",
    "  for (size_t i = 0; i < dataset.n_cols - rho; i++)\n",
    "  {\n",
    "    X.subcube(arma::span(), arma::span(i), arma::span()) =\n",
    "        dataset.submat(arma::span(), arma::span(i, i + rho - 1));\n",
    "    y.subcube(arma::span(), arma::span(i), arma::span()) =\n",
    "        dataset.submat(arma::span(3, 4), arma::span(i + 1, i + rho));\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "// We need to individually create training and testing time series data.\n",
    "arma::cube trainX, trainY, testX, testY;\n",
    "trainX.set_size(inputSize, trainData.n_cols - rho + 1, rho);\n",
    "trainY.set_size(outputSize, trainData.n_cols - rho + 1, rho);\n",
    "testX.set_size(inputSize, testData.n_cols - rho + 1, rho);\n",
    "testY.set_size(outputSize, testData.n_cols - rho + 1, rho);\n",
    "\n",
    "// Create training sets for one-step-ahead regression.\n",
    "CreateTimeSeriesData(trainData, trainX, trainY, rho);\n",
    "// Create test sets for one-step-ahead regression.\n",
    "CreateTimeSeriesData(testData, testX, testY, rho);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Model\n",
    "\n",
    "We add 3 LSTM modules that will be stacked one after the other in the RNN, implementing an efficient stacked RNN. Finally, the output will have 2 units the (high, low) values of the stock price for the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpack::ann::RNN<mlpack::ann::MeanSquaredError<>, mlpack::ann::RandomInitialization> model(rho);\n",
    "\n",
    "if (bLoadAndTrain)\n",
    "{\n",
    "  // The model will be trained further.\n",
    "  std::cout << \"Loading and further training model...\" << std::endl;\n",
    "  data::Load(modelFile, \"LSTMMulti\", model);\n",
    "}\n",
    "else\n",
    "{\n",
    "  model.Add<mlpack::ann::IdentityLayer<> >();\n",
    "  model.Add<mlpack::ann::LSTM<> >(inputSize, H1, maxRho);\n",
    "  model.Add<mlpack::ann::Dropout<> >(0.5);\n",
    "  model.Add<mlpack::ann::LeakyReLU<> >();\n",
    "  model.Add<mlpack::ann::LSTM<> >(H1, H1, maxRho);\n",
    "  model.Add<mlpack::ann::Dropout<> >(0.5);\n",
    "  model.Add<mlpack::ann::LeakyReLU<> >();\n",
    "  model.Add<mlpack::ann::LSTM<> >(H1, H1, maxRho);\n",
    "  model.Add<mlpack::ann::LeakyReLU<> >();\n",
    "  model.Add<mlpack::ann::Linear<> >(H1, outputSize);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Training the model.\n",
    "\n",
    "We will use ensmallen to get the optimizer and train the model. For more details refer to the [documentation](https://www.ensmallen.org/docs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Setting parameters Stochastic Gradient Descent (SGD) optimizer.\n",
    "ens::SGD<ens::AdamUpdate> optimizer(\n",
    "    STEP_SIZE, // Step size of the optimizer.\n",
    "    BATCH_SIZE, // Batch size. Number of data points that are used in each iteration.\n",
    "    trainData.n_cols * EPOCHS, // Max number of iterations.\n",
    "    1e-8,// Tolerance.\n",
    "    true, // Shuffle.\n",
    "    ens::AdamUpdate(1e-8, 0.9, 0.999)); // Adam update policy.\n",
    "\n",
    "optimizer.Tolerance() = -1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch 1/2433\n",
      "nan42 [====================================================================================================] 100% - ETA: 0s - loss: nan2494\n",
      "42/42 [====================================================================================================] 100% - 13s 328ms/step - loss: nan\n"
     ]
    }
   ],
   "source": [
    "// Train the model.\n",
    "if (bTrain)\n",
    "{\n",
    " std::cout << \"Training ...\" << std::endl;\n",
    "\n",
    " model.Train(trainX,\n",
    "             trainY,\n",
    "             optimizer,\n",
    "             // PrintLoss Callback prints loss for each epoch.\n",
    "             ens::PrintLoss(),\n",
    "             // Progressbar Callback prints progress bar for each epoch.\n",
    "             ens::ProgressBar(),\n",
    "             // Stops the optimization process if the loss stops decreasing\n",
    "             // or no improvement has been made. This will terminate the\n",
    "             // optimization once we obtain a minima on training set.\n",
    "             ens::EarlyStopAtMinLoss());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in lstm_multi.bin\n"
     ]
    }
   ],
   "source": [
    "// Save the model.\n",
    "mlpack::data::Save(modelFile, \"LSTMMulti\", model);\n",
    "std::cout << \"Model saved in \" << modelFile << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the Trained Model and Run Inference.\n",
    "\n",
    "Load the the model with saved weights and run inference on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    }
   ],
   "source": [
    "mlpack::ann::RNN<mlpack::ann::MeanSquaredError<>, mlpack::ann::RandomInitialization> trainedModel(rho);\n",
    "std::cout << \"Loading model ...\" << std::endl;\n",
    "mlpack::data::Load(modelFile, \"LSTMMulti\", trainedModel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Run Inference.\n",
    "arma::cube predOutP;\n",
    "trainedModel.Predict(testX, predOutP);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the validation loss.\n",
    "\n",
    "For this purpose we will be calculating Mean Squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Function to calcute MSE for arma::cube.\n",
    " */\n",
    "double MSE(arma::cube &pred, arma::cube &Y)\n",
    "{\n",
    "  return metric::SquaredEuclideanDistance::Evaluate(pred, Y) / (Y.n_elem);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Prediction data points:= nan\n"
     ]
    }
   ],
   "source": [
    "// Calculate error on predicted data.\n",
    "double testMSEP = MSE(predOutP, testY);\n",
    "std::cout << \"Mean Squared Error on Prediction data points:= \" << testMSEP << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the results.\n",
    "Since the predicted is in form of a cube we need to convert it to matrix with predicted values. Then we take the inverse transform to convert it to meaningful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * This function saves the input data for prediction and the prediction results\n",
    " * in CSV format. The prediction results are the (high, low) for the next day\n",
    " * and come from the last slice of the prediction. The last 2 columns are the\n",
    " * predictions; the preceding columns are the data used to generate those\n",
    " * predictions.\n",
    " */\n",
    "void SaveResults(const std::string filename,\n",
    "                 const arma::cube& predictions,\n",
    "                 data::MinMaxScaler& scale,\n",
    "                 const arma::cube& testX)\n",
    "{\n",
    "  arma::mat flatDataAndPreds = testX.slice(testX.n_slices - 1);\n",
    "\n",
    "  // The prediction results are the (high, low) for the next day and come from\n",
    "  // the last slice from the prediction.\n",
    "  flatDataAndPreds.rows(flatDataAndPreds.n_rows - 2,\n",
    "                        flatDataAndPreds.n_rows - 1) = predictions.slice(predictions.n_slices - 1);\n",
    "\n",
    "  scale.InverseTransform(flatDataAndPreds, flatDataAndPreds);\n",
    "\n",
    "  // We need to remove the last column because it was not used for training\n",
    "  // (there is no next day to predict).\n",
    "  flatDataAndPreds.shed_col(flatDataAndPreds.n_cols - 1);\n",
    "\n",
    "  // Save the data to file. The last columns are the predictions; the preceding\n",
    "  // columns are the data used to generate those predictions.\n",
    "  mlpack::data::Save(filename, flatDataAndPreds);\n",
    "\n",
    "  // Print the output to screen.\n",
    "  // NOTE: we do not have the last data point in the input for the prediction\n",
    "  // because we did not use it for the training, therefore the prediction result\n",
    "  // will be for the day before. In your own application you may of course load\n",
    "  // any dataset for prediction.\n",
    "  std::cout << \"The predicted Google stock (high, low) for the last day is: \" << std::endl;\n",
    "  std::cout << \"  (\" << flatDataAndPreds(flatDataAndPreds.n_rows - 2, flatDataAndPreds.n_cols - 1) << \", \";\n",
    "  std::cout << flatDataAndPreds(flatDataAndPreds.n_rows - 1, flatDataAndPreds.n_cols - 1) << \")\" << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Google stock (high, low) for the last day is: \n",
      "  (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "// Save the output predictions and show the results.\n",
    "SaveResults(predFile, predOutP, scale, testX);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
